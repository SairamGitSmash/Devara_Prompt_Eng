{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-Shot Prompting\n",
    "\n",
    "Zero-shot prompting refers to a technique in prompt engineering where you provide a model with a task without any prior examples. The model is expected to understand and generate a response or complete the task purely based on the given instruction.\n",
    "\n",
    "In other words, the model is given \"zero\" prior training examples or demonstrations in the prompt and relies on its pre-trained knowledge to infer what is needed.\n",
    "\n",
    "## References:\n",
    "* [Wei et al. (2022)](https://arxiv.org/pdf/2109.01652.pdf): demonstrate how instruction tuning improves zero-shot learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running this code on MyBind.org\n",
    "\n",
    "Note: remember that you will need to **adjust CONFIG** with **proper URL and API_KEY**!\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/GenILab-FAU/prompt-eng/HEAD?urlpath=%2Fdoc%2Ftree%2Fprompt-eng%2Fzero_shot.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2:latest', 'prompt': 'Extract a detailed list of functional and non-functional requirements for the following system:\\n\\nIdentify and categorize functional and non-functional requirements for an AI-powered Study Companion Bot for Discord.', 'stream': False, 'options': {'temperature': 1.0, 'num_ctx': 100, 'num_predict': 100}}\n",
      "Here is a detailed list of functional and non-functional requirements for the AI-powered Study Companion Bot for Discord:\n",
      "\n",
      "**Functional Requirements:**\n",
      "\n",
      "1. **Registration and Authentication**\n",
      "\t* Users can register with a unique username and email address.\n",
      "\t* Users can log in to the bot using their registered credentials.\n",
      "2. **Study Material Sharing**\n",
      "\t* Users can share study materials (e.g., notes, videos, PDFs) with each other.\n",
      "\t* Users can request specific materials from others.\n",
      "3\n",
      "Time taken: 22.211s\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## ZERO SHOT PROMPTING FOR SOFTWARE REQUIREMENT EXTRACTION\n",
    "##\n",
    "\n",
    "from _pipeline import create_payload, model_req\n",
    "from logging_setup import log_request, log_response\n",
    "\n",
    "class ZeroShotPrompting:\n",
    "    def __init__(self):\n",
    "        self.class_name = self.__class__.__name__\n",
    "\n",
    "    def run(self):\n",
    "        #### (1) Adjust the inbounding Prompt, simulating inbounding requests from users or other systems\n",
    "        MESSAGE = \"Identify and categorize functional and non-functional requirements for an AI-powered Study Companion Bot for Discord.\"\n",
    "\n",
    "        #### (2) Adjust the Prompt Engineering Technique to be applied, simulating Workflow Templates\n",
    "        PROMPT = f\"Extract a detailed list of functional and non-functional requirements for the following system:\\n\\n{MESSAGE}\"\n",
    "\n",
    "        #### (3) Configure the Model request, simulating Workflow Orchestration\n",
    "        payload = create_payload(\n",
    "            target=\"ollama\",\n",
    "            model=\"llama3.2:latest\", \n",
    "            prompt=PROMPT, \n",
    "            temperature=1.0, \n",
    "            num_ctx=100, \n",
    "            num_predict=100\n",
    "        )\n",
    "\n",
    "        # Send out to the model\n",
    "        time, response = model_req(payload=payload)\n",
    "        print(response)\n",
    "        if time:\n",
    "            print(f'Time taken: {time}s')\n",
    "\n",
    "        # Pass the class name for logging\n",
    "        log_request({\"class\": self.class_name, \"payload\": payload})\n",
    "        log_response(time, {\"class\": self.class_name, \"response\": response})\n",
    "\n",
    "# Run the pipeline\n",
    "pipeline = StudyBotPipeline()\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## How to improve it?\n",
    "\n",
    "* **Use Clear and Concise Instructions**: Be specific about the task and desired format.\n",
    "    * Bad Prompt: “Summarize this.”\n",
    "    * Good Prompt: “Summarize this paragraph in one sentence.”\n",
    "* **Add Context**: Providing background can help the model interpret ambiguous prompts better.\n",
    "* **Specify Output Format**: If a particular structure is needed, describe it in the instruction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
